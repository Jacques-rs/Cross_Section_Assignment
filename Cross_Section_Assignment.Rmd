---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Cross Section Assignment"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Nico Katzke}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Jacques Rossouw"  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "Stellebosch, Western Cape, South Africa" # First Author's Affiliation
Email1: "gerardrossouw\\@gmail.com" # First Author's Email address

# Author2: "John Smith"
# Ref2: "Some other Institution, Cape Town, South Africa"
# Email2: "John\\@gmail.com"
# CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.
# 
# Author3: "John Doe"
# Email3: "Joe\\@gmail.com"
# 
# CorrespAuthor_1: TRUE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE
# 
# # Comment out below to remove both. JEL Codes only given if keywords also given.
# keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
# JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
# Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: FALSE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
# abstract: |
#   Abstract to be written here. The abstract should not be too long and should provide the reader with a good understanding what you are writing about. Academic papers are not like novels where you keep the reader in suspense. To be effective in getting others to read your paper, be as open and concise about your findings here as possible. Ideally, upon reading your abstract, the reader should feel he / she must read your paper in entirety.
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf.
# These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!
library(pacman)

pacman::p_load(tidyverse, dplyr, lubridate, AER, 
               broom, plm, corrplot, psych, ggrepel,
               gridExtra)

fmxdat::source_all("./code")

```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->



```{r View continents}

continents <- extract_continents()

```



```{r}


# number_countries <- read_csv(file = "./data/owid-covid-data.csv",
#                           show_col_types = F) %>%
#     filter(!location %in% c(continents)) %>%
#     filter(date == first(date)) %>% 
#     select(location) %>% 
#     nrow()
```


```{r}
# quick_check2 <-  read_csv(file = "./data/owid-covid-data.csv",
#                           show_col_types = F) %>% 
#     group_by(location) %>% 
#     filter(date == first(date)) %>% 
#     ggplot() + 
#     geom_point(aes(x = location, y = date)) +
#     geom_hline(yintercept = lubridate::ymd(20200430), color = "red")
#     
# 
# quick_check2
```


```{r}
# number_countries_incl <- read_csv(file = "./data/owid-covid-data.csv",
#                           show_col_types = F) %>% 
#     group_by(location) %>% 
#     filter(!location %in% c(continents)) %>% 
#     filter(date == first(date)) %>% 
#     filter(!is.na(continent)) %>% 
#     filter(date <= lubridate::ymd(20200430)) %>% 
#     select(location) %>% 
#     unique()
```


```{r}
# read_csv(file = "./data/owid-covid-data.csv",
#                           show_col_types = F) %>% 
#     group_by(location) %>% 
#     filter(!location %in% c(continents)) %>% 
#     filter(!is.na(continent)) %>% 
#     filter(first(date) <= lubridate::ymd(20200430)) %>% 
#     filter(date == first(date)) %>% 
#     select(location)



```


Want to compare the US, with Europe, Africa (excluding SA), and SA (and maybe Asia, or specifically china)

```{r}
continents
```


```{r South Africa}
rm(continents)
# sa_df <- extract_sa_alt(country = "South Africa")
# africa_df <- extract_sa(cont = "Africa")


# sa_df_alt <- extract_sa_alt(country = "South Africa")  
# africa_df_alt <- extract_sa_alt(cont = "Africa")


```


```{r }

# Tests seems to have started from the first observation of the
# dataset so all information might be relevant
# sa_df %>% 
#     mutate(test_date = if_else(!is.na(total_cases), sa_df$date, lubridate::ymd(20000101))) %>% 
#     select(date, test_date) %>% ggplot() +
#     geom_point(aes(x = date, y = test_date), color = "red",
#                size = 0.5) #+
#     #xlim(first(sa_df$date), last(sa_df$date))


```


[Share of woman vs men](https://www.statista.com/statistics/967928/total-population-of-south-africa-by-gender/) in SA about equal

```{r Additional Features We Do Not Want}

# sa_df <- feature_adj(sa_df)
# africa_df <- feature_adj(africa_df)
    
# sa_df_alt <- feature_adj_alt(sa_df_alt)
# africa_df_alt <- feature_adj_alt(africa_df_alt)


```


```{r format for Regression}

fmxdat::source_all("./code")

# sa_df <- regression_format_country(sa_df)
# africa_df <- regression_format_country(africa_df)

# sa_df_alt <- regression_format_country_alt(sa_df_alt)
# africa_df_alt <- regression_format_country_alt(africa_df_alt)


```



```{r}
fmxdat::source_all("./code")

# africa_df_alt <- africa_df_alt %>%  experiment_aggregate(.) %>% 
#     experiment_trim(.)

```




We need to have a look at the correlation between the different variables
to see what type of relationships exist. 
Furthermore, it is important to 
<!-- determine correlations beyond mere linear correlations. -->

```{r, fig.height=10, fig.width=10}

# africa_df_alt %>% filter()
# 
# africa_df_alt %>% ungroup() %>% select(-c(location, date, continent, 
#                                           day_of_week, smokers, hosp_patients)) %>% 
#     cor(.) %>% 
#     corrplot(., method = "pie", order = "hclust", tl.srt=45, diag = F)

```



```{r}
# OLS_model1 <- plm(africa_df_alt$death_rate ~ africa_df_alt$stringency_index,
#                   index = c("location", "date"), data = africa_df_alt, model = "pooling")
# 
# OLS_model2 <- plm(africa_df_alt$death_rate ~ africa_df_alt$stringency_index + africa_df_alt$aged_65_older + africa_df_alt$population_density + africa_df_alt$gdp_per_capita + africa_df_alt$extreme_poverty + africa_df_alt$diabetes_prevalence + africa_df_alt$smokers + africa_df_alt$handwashing_facilities + africa_df_alt$life_expectancy + africa_df_alt$human_development_index, data = africa_df_alt, 
#                   index = c("location", "date"), model = "pooling")
# 
# tidy(OLS_model2) %>% mutate(across(names(.[2:5]), function(x) round(x = x, digits = 3)))
# 
# 
# # ; glance(OLS_model2)
# 
# summary(OLS_model2)
```


```{r}
fmxdat::source_all("./code")

# sa_df_alt <- sa_df_alt %>%  experiment_aggregate(.) %>% 
#     experiment_trim(.)
```



```{r}
fmxdat::source_all("./code")
# New vaccinations is transformed to new_vaccinations relative to population size
# i.e. per 1000 people
# Same goes for new_tests
# hosp_paitents, per 1000000
# as well as icu

world_df <- extract_all() %>% 
    feature_adj_all() %>% 
    experiment_aggregate_week() %>% 
    experiment_trim() %>% 
    relocate(death_rate, .before = reproduction_rate)

```


```{r,Check range of variying columns}
options(scipen=999)
fmxdat::source_all("./code")

cols_range(world_df)
options(scipen=0)
```


```{r}

fmxdat::source_all("./code")

world_df <- world_df %>% scale_bigs_cumsum(.)


```



```{r,Check range of variying columns}
options(scipen=999)
fmxdat::source_all("./code")

cols_range(world_df)
options(scipen=0)
```


Thus, want to scale: `hosp_patients, new_test, new_vaccinations`


```{r}



# world_df %>% gather(big, big_cols,
#                     c("icu_patients", "hosp_patients",
#                       "new_tests", "new_vaccinations")) %>%
#     ggplot()



world_df %>% ungroup() %>% group_by(location) %>% 
    mutate(label = if_else(date == last(date), as.character(location), NA_character_)) %>% 
    # filter(date == last(date)) %>% 
    ggplot(aes(x = date, y = new_tests, group = location, col = location)) +
    geom_line() +
    theme(axis.text.x = element_text(size = 10),
      axis.title = element_text(face = "bold"),
      axis.line = element_line(colour = "grey50", size = 1)) +
    scale_y_continuous("cumulative_new_tests_per_1000") +
    labs(title = "Plot name") +
    geom_label_repel(aes(label = label),
              nudge_x = 1,
              na.rm = TRUE) +
    theme(legend.position="none")


```


```{r}
world_df %>% ungroup() %>% group_by(location) %>% 
    mutate(label = if_else(date == last(date), as.character(location), NA_character_)) %>% 
    # filter(date == last(date)) %>% 
    ggplot(aes(x = date, y = new_vaccinations, group = location, col = location)) +
    geom_line() +
    theme(axis.text.x = element_text(size = 10),
      axis.title = element_text(face = "bold"),
      axis.line = element_line(colour = "grey50", size = 1)) +
    scale_y_continuous("cumulative_new_vaccinations_per_1000") +
    labs(title = "Plot name") +
    geom_label_repel(aes(label = label),
              nudge_x = 1,
              na.rm = TRUE) +
    theme(legend.position="none")
```


```{r}
world_df %>% ungroup() %>% group_by(location) %>% 
    mutate(label = if_else(date == last(date), as.character(location), NA_character_)) %>% 
    # filter(date == last(date)) %>% 
    ggplot(aes(x = date, y = hosp_patients, group = location, col = location)) +
    geom_line() +
    theme(axis.text.x = element_text(size = 10),
      axis.title = element_text(face = "bold"),
      axis.line = element_line(colour = "grey50", size = 1)) +
    scale_y_continuous("hosp_patients_per_1000") +
    labs(title = "Plot name") +
    geom_label_repel(aes(label = label),
              nudge_x = 1,
              na.rm = TRUE) +
    theme(legend.position="none")
```


```{r}
world_df %>% ungroup() %>% group_by(location) %>% 
    mutate(label = if_else(date == last(date), as.character(location), NA_character_)) %>% 
    # filter(date == last(date)) %>% 
    ggplot(aes(x = date, y = icu_patients, group = location, col = location)) +
    geom_line() +
    theme(axis.text.x = element_text(size = 10),
      axis.title = element_text(face = "bold"),
      axis.line = element_line(colour = "grey50", size = 1)) +
    scale_y_continuous("icu_patients_per_1000") +
    labs(title = "Plot name") +
    geom_label_repel(aes(label = label),
              nudge_x = 1,
              na.rm = TRUE) +
    theme(legend.position="none")
```


```{r}
world_df <- world_df %>% scale_bigs_scale()
```




Now, to check the scales of the features that remain constant per country:

```{r}

cols_range_constant(world_df)

```

Additional features that need to be scaled are this

- `gdp_per_capita`
- `population_density`
- `cardiovasc_death_rate`

```{r}
# first, double check cardiovascular death rate

# constant_features = c("gdp_per_capita", "population_density",
#                                                            "median_age", "aged_65_older",
#                                                            "extreme_poverty",
#                                                       "cardiovasc_death_rate",
#                                                            "diabetes_prevalence",
#                                                       "handwashing_facilities",
#                                                            "hosp_beds_1k", "life_expectancy",
#                                                            "human_development_index", "smokers")

# world_df %>% ungroup() %>% gather("location", constants, vars(c("location", constant_features)))

g1 <- world_df %>% ungroup() %>% group_by(location) %>% 
    filter(date == last(date)) %>% 
    ggplot() +
    geom_point(aes(x = reorder(location, cardiovasc_death_rate, mean), y = cardiovasc_death_rate)) +
    theme(axis.text.x = element_blank(),
      axis.title = element_text(face = "bold"),
      axis.line = element_line(colour = "grey50", size = 1)) +
    scale_y_continuous("Cardiovascular Death Rate") +
    scale_x_discrete("Country") +
    labs(title = "Cardiovascular Death Rate")
         # subtitle = "More or less linear i.e. normalisation scaling")

```




```{r}
g2 <- world_df %>% ungroup() %>% group_by(location) %>% 
    filter(date == last(date)) %>% 
    ggplot() +
    geom_point(aes(x = reorder(location, gdp_per_capita, mean), y = gdp_per_capita)) +
    theme(axis.text.x = element_blank(),
      axis.title = element_text(face = "bold"),
      axis.line = element_line(colour = "grey50", size = 1)) +
    scale_y_continuous("GDP per Capita") +
        scale_x_discrete("Country") +
    labs(title = "GDP per capita")
         # subtitle = "Nonlinear distribution suggests a\nlog transformation")

```

```{r}
g3 <- world_df %>% ungroup() %>% group_by(location) %>% 
    filter(date == last(date)) %>% 
    ggplot() +
    geom_point(aes(x = reorder(location, population_density, mean), y = population_density)) +
    theme(axis.text.x = element_blank(),
      axis.title = element_text(face = "bold"),
      axis.line = element_line(colour = "grey50", size = 1)) +
    scale_y_continuous("Population Density") +
    scale_x_discrete("Country") +
    labs(title = "Population Density")
         # subtitle = "Presence of outliers suggests scaling\nsuch that outliers remain\nrelatively present, i.e. normalisation")
```


```{r}

grid.arrange(g1, g2, g3, nrow=2)

```



```{r}

world_df <- world_df %>% scale_bigs_constant(.)
    

```


Now we can check all the descriptive stats for all the columns

```{r}
options(scipen=999)
world_df %>% cols_range(df = ., constant_features = c("location", "date"))
options(scipen=0)
```


```{r}
mod_ols_1 <- plm(world_df$death_rate ~ world_df$stringency_index,
                  index = c("location", "date"), data = world_df, model = "pooling")

# world_df %>% 
#     mutate(year_quarter = paste(year(date), quarter(date), sep = "")) %>% 
#     relocate(year_quarter, .before = date) %>% 
#     dummy.code(year_quarter)

add_year_dummy <- function(df){
    
    mutate()
    
}

# mod_ols_2 <- plm()

mod_ols_3 <- plm(world_df$death_rate ~ world_df$stringency_index + world_df$aged_65_older + world_df$gdp_per_capita + world_df$extreme_poverty + world_df$diabetes_prevalence + world_df$smokers + world_df$handwashing_facilities + world_df$life_expectancy + world_df$human_development_index, data = world_df,
                  index = c("location", "date"), model = "pooling")

# tidy(mod_ols_2) %>% mutate(across(names(.[2:5]), function(x) round(x = x, digits = 3)))


# ; glance(mod_ols_2)

summary(mod_ols_3)
```





