---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Cross Section Assignment - The Effect of Lockdowns on the Severity Covid-19"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Nico Katzke}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Jacques Rossouw"  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "Stellebosch, Western Cape, South Africa" # First Author's Affiliation
Email1: "gerardrossouw\\@gmail.com" # First Author's Email address

# Author2: "John Smith"
# Ref2: "Some other Institution, Cape Town, South Africa"
# Email2: "John\\@gmail.com"
# CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.
# 
# Author3: "John Doe"
# Email3: "Joe\\@gmail.com"
# 
# CorrespAuthor_1: TRUE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE
# 
# # Comment out below to remove both. JEL Codes only given if keywords also given.
# keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
# JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
# Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: TRUE         # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt    # Set fontsize
linestretch: 1.2  # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: FALSE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
---

<!-- First: default preferences for chunk options: -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
        fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H',
        purl = TRUE)

pacman::p_load(tidyverse, dplyr, lubridate, AER, 
 broom, plm, corrplot, psych, ggrepel,
 gridExtra, stargazer, formatR)

fmxdat::source_all("./code")

```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->


\newpage

# Introduction


The effects of the covid-19 corona virus has led to global economic strain and
the debate over whether strict lockdown rules were necessary inspite of their 
economic implications is debated by some. 

The problem with identifying the effect that covid policy stringency had on
covid-19 is with the idiosynctratic differences between countries that also 
contributed to the severity of how covid would have affected individuals. 
This suggests that the fixed effects regression technique offers a unique 
opportunity to account for these fixed effects between countries, and to isolate
the effect that policy had on covid. Towards fighting the coronavirus as 
a different flu from the typical cold, the amount of people hospitalised, 
those ending up in ICU, or deaths per unit of time is measured relative to 
the amount of new cases. The typical flu also spreads rapidly but the the
problem is set up as mentioned, to isolate the effect over and above being
a standard flu.

By using the data from @dataset, the data is first cleaned by filtering for 
only the country components, and removing the countries for which data does 
not exist after a certain date.

<!-- Note: All functional code is contained in the appendix -->


# Data Cleaning/Feature Selection

```{r View continents, appendix = T, include=FALSE}

# Checking the date of first observations
start_date()

```


Some transformations are also made to columns to make them more usable for 
regression. The variables that are distributed on a wider range, or scale, 
are also scaled to ensure that the OLS estimation is not biased by this. The
code in the [Appendix] illustrates this.

```{r Fetch, echo=FALSE, include=FALSE, purl=TRUE}

# fetching and cleaning the dataset
world_df <- extract_all() %>% 
    feature_adj_all() %>% 
    experiment_aggregate_week() %>% 
    experiment_trim() %>% 
    relocate(afflicted_rate, .before = reproduction_rate)

world_df
```


## Converting to Cumulative Values


```{r echo=TRUE}
# See appendix
world_df <- world_df %>% scale_bigs_cumsum(.)
```

## Variable Features Scaling

```{r range_var, echo=FALSE}
options(scipen=999)
cols_range(world_df)
options(scipen=0)
```

Thus, want to scale: `new_test, new_vaccinations`

Plotting to see whether there is any irregularity in the distribution of the dependent variable.

```{r afflicted, echo=FALSE}
a1 <- afflicted_plot(world_df)
a2 <- stringency_plot(world_df)
grid.arrange(a1, a2, ncol=2)
```


```{r var_plot, echo=FALSE}
p1 <- cumulative_test_plot(world_df)
p2 <- cumulative_vax_plot(world_df)
grid.arrange(p1, p2, ncol=2)
```


```{r scale_var, echo=TRUE}
world_df <- world_df %>% scale_bigs_scale(.)
```


## Fixed Effects Feature Scaling

Now, to check the scales of the features that remain constant per country:

```{r range_cons, echo=FALSE}
cols_range_constant(world_df)
```

Additional features that need to be scaled are this
- `gdp_per_capita`
- `population_density`
- `cardiovasc_death_rate`

```{r cons_plot, echo=FALSE}

g1 <- cardio_plot(world_df)
g2 <- gdp_plot(world_df)
g3 <- pop_density_plot(world_df)
grid.arrange(g1, g2, g3, nrow=2)
```

The non-linear distribution of Real GDP suggests a transformation. Presence 
of outliers and large range in `population_density` suggests normalisation 
scaling. The same goes for the cardiovascular death rate.

```{r scale_cons, echo=TRUE}
world_df <- world_df %>% scale_bigs_constant(.)
```


The value of the stringency index is assumed to have a delayed effect on the 
coronavirus, therefore, to account for this, one quarter lagged average 
stringency index value is associated the current with each current period. 

```{r lag}
world_df <- world_df %>%
    group_by(location) %>%
    mutate(across(date, function(x) floor_date(x, unit = "quarters"))) %>% 
    ungroup()
    
quick_df <- world_df %>%
    select(location, date, stringency_index) %>% 
    group_by(location) %>% 
    mutate(across(date, function(x) x %m+% months(3))) %>% 
    filter(date != last(date))

world_df <- quick_df %>% left_join(world_df, by = c("location", "date")) %>% 
    select(-stringency_index.y)
```


# Correlation Analysis


```{r cor_plot, echo=FALSE}
cor_plot1(world_df)$arg$type
```

```{r core_plot2, echo=FALSE, message=FALSE, warning=FALSE}
cor_plot2(world_df)$arg$type
```



```{r include=FALSE}
names(world_df)
```

The components that will form a part of the larger OLS regression is therefore
the:

- stringency index `stringency_index.x`

<!-- - average life expectancy `life_expectancy` -->

- development index `human_development_index`

- proportion of smokers `smokers`

- population over the age of 65 `aged_65_older`

- and hospital beds per 1000 `hosp_beds_1k`

- Availability of hand washing facilities `handwashing_facilities`


Hand washing facilities is added based on intuitive interpretation

# Regressions

## OLS Regression

```{r OLS}
mod_ols_1 <- plm(afflicted_rate ~ stringency_index.x +
   handwashing_facilities + reproduction_rate,
    index = c("location", "date"), data = world_df, 
   model = "pooling")

mod_ols_2 <- plm(afflicted_rate ~ stringency_index.x + smokers
   + handwashing_facilities + aged_65_older + hosp_beds_1k
   + human_development_index + reproduction_rate 
   + new_vaccinations_cum_per_1000, 
   data = world_df, 
   index = c("location", "date"), model = "pooling")

mod_1sls <- plm(stringency_index.x ~ gdp_per_capita_log 
                + population_density_norm,
                data = world_df, 
                index = c("location", "date"), model = "pooling")

stringency_hat <- fitted.values(mod_1sls)

mod_2sls <- plm(afflicted_rate ~ stringency_hat + smokers
   + handwashing_facilities + aged_65_older + hosp_beds_1k
   + human_development_index + new_vaccinations_cum_per_1000, 
   data = world_df, 
   index = c("location", "date"), model = "pooling")

# To get robust standard errors
robustse_ols1 <- sqrt(diag(vcovHC(mod_ols_1, type = "HC1")))
robustse_ols2 <- sqrt(diag(vcovHC(mod_ols_2, type = "HC1")))
robustse_2sls <- sqrt(diag(vcovHC(mod_2sls, type = "HC1")))

```


```{r ols_star, results='asis', message=F, comment='%', tidy=T}

stargazer(mod_ols_1, mod_ols_2, mod_2sls, header = F,
          font.size = "footnotesize", se = list(robustse_ols1,
         robustse_ols2,
         robustse_2sls), column.labels = c("OLS", 
                                             "OLS",
                                             "2SLS"))

```


## Fixed- and Random Effects Regression


```{r FE}

mod_fe_1 <- plm(afflicted_rate ~ stringency_index.x + smokers
   + handwashing_facilities + aged_65_older + hosp_beds_1k
   + human_development_index + new_vaccinations_cum_per_1000, 
   data = world_df, 
   index = c("location"), 
  model = "within", effect = "individual")


robustse_fe1 <- sqrt(diag(vcovHC(mod_fe_1, type = "HC1")))

```


```{r RE}
mod_re_1 <- plm(afflicted_rate ~ stringency_index.x + smokers
   + handwashing_facilities + aged_65_older + hosp_beds_1k
   + human_development_index + new_vaccinations_cum_per_1000,
                   data = world_df,
                   index = c("location"),
                  model = "random", effect = "individual")

robustse_re1 <- sqrt(diag(vcovHC(mod_re_1, type = "HC1")))
phtest(mod_fe_1, mod_re_1)
```


```{r fe_star, results='asis', message=F, comment='%', tidy=T}
stargazer(mod_fe_1, mod_re_1, header = F,
          font.size = "small", se = list(robustse_re1), column.labels = c("FE", 
                                             "RE"))
```


```{r}
knitr::kable(tidy(pFtest(mod_fe_1, mod_2sls)), caption=
        "Fixed effects test: Ho:'No fixed effects'")
```


## Interpretations

It is not surprising that the health measures such as proportion the of smokers 
larger older generations had a significant impact on the amount of individuals
that were afflicted from covid. This holds for the OLS, 2SLS, and the RE model. 
It is surprising, however, that the availability of handwashing facilities had 
no significant impact, except for in the RE model.

The Hausman test results in a p-value of 0.8877 which implies the null 
hypothesis cannot be rejected and either model, RE or FE is consistent, however,
RE is more efficient. 

Table 4.3 illustrates the motivation for the use of a fixed effects model.
The `pFtest` compares OLS with Fixed Effects. The result suggests a rejection
of the null in favour of the Fixed effects model. That is, there exists
fixed effects whitin the data.

Most importantly, independent of which model is chosen, there seems to be no
significance between the stringency index and afflicted rate. The models
presented here offer variable approaches to analysing the causal effect.
The results should not be taken verbatim, however. There are alternative
non-parametric models hat can allow for a more accurate anaylisis. Similar
attempts have been made, such as the recen paper by @ML. Their methods 
also suggest a machine learning based model can offer an ideal substitute.
Based on the results from above, the lockdown measures did not have a significant
impact on those individuals severly affected by Covid-19, over and above the 
normal effects of a widespread flu.


### Measurement Error & Bias

It is important to note that the unexpected nature of Covid-19 resulted in
a lot of "on the fly" data collection which can lead to larger measurement 
errors. The reliability of measurement error and false estimates in this case 
is questionable. Furthermore, the fixed- and random effects regressions can
exacerbate this problem. In that case, it would suggest that a pooled OLS 
regression offer some particular benefits.

### Assumptions of OLS:

There exists an inherent endogeneity in this dataset, since there exists some
country specific factors that might have led to lockdowns being more effective
or having more resources to withstand the aderse effects of lockowns. For this
reason, the last OLS model includes a two stage least squares regression model
to mitigate this issue. Additionally, the Random- and Fixed effects models are
also fitted. These can more precisely account for country specific factors 
playing a role.

The Instrumental Variable regression, by method of two stage least squares, 
requires the following assumptions to hold for an unbiased estimate:

Instrument Variable:  real GDP, and population density, such that they affect
the afflicted rate through the stringency index

1. Exclusion Restriction

This requires that the real GDP, and population density only affects the 
afflicted rate through the stringency index.

This assumption very likely to holds. There is no reason to believe that real
GDP affects the afflicted rate per ten thousand individuals in the population.
There is however, a possibility that population density has an effect on
this.

2. Random Assignment

This requires that there be no difference between the potential outcomes


3. Instrument Relevance

This requires that real GDP and population density actually have a significant
effect on the the stringency index value. Intuitively, this should be the case
since wealthier countries have more resources to apply stricter rules and more
densely populated areas ought to require more strict policy to combat the 
effects if Covid-19.

4. Monotonicity

Whether any country could be expected to have endorsed less strict policy
based on their high real GDP or high population density.

For the latter case, this is unlikely the case. However, some countries might
have been more relaxed from having more resources to cope with the effects
of Covid.


### Assumptions of Fixed- and Random Effects

The assumptions that need to hold here, include:

1. Type of Unconfoundedness

Conditioning on the fixed effects per country (and other covariates), there 
should be no other reason for selection into treatment, i.e. having more 
stringent policy. This does seem likely to hold.

2. Same Time Trends

There is no way to assert that this assumption holds with certainty. 


# Concluion

There does not seem to be a significant causal effect of the level of strictness
regarding covid lockdown and the rate of afflicted individuals per ten thousand
people in a population. There exists some room for improvement on the models
presented hre. Perhaps a non-linear model such as a machine learning based 
option would yield more accurate results.

\newpage

# References

<div id="refs"></div>

\newpage

# Appendix

```{r get-labels, echo = FALSE}
labs = knitr::all_labels()
labs = setdiff(labs, c("setup","get-labels", "function_scripts",
                       "fe_star", "ols_star", "FE", "RE", "OLS",
                       "cor_plot", "descr", "scale_cons", "cons_plot",
                       "range_cons", "scale_var", "var_plot", "afflicted",
                       "range_var"))
```

```{r all-code, ref.label=labs, eval=FALSE}
```


## Functional Code

```{r function_scripts, echo=FALSE}

afflicted_plot
cardio_plot
cols_range 
cols_range_constant 
cor_plot1
cor_plot2
cumulative_test_plot  
cumulative_vax_plot  
experiment_aggregate_week
experiment_trim 
extract_all
extract_continents  
feature_adj_all 
gdp_plot
pop_density_plot
scale_bigs_constant
scale_bigs_cumsum  
scale_bigs_scale
start_date
```
